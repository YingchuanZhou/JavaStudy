# Docker 高级

# Docker Compose

## 简介

![在这里插入图片描述](29.Docker%E9%AB%98%E7%BA%A7.assets/20201205173610891.png)

![在这里插入图片描述](29.Docker%E9%AB%98%E7%BA%A7.assets/20201205173621230.png)

![在这里插入图片描述](29.Docker%E9%AB%98%E7%BA%A7.assets/2020120517363870.png)

![在这里插入图片描述](29.Docker%E9%AB%98%E7%BA%A7.assets/20201205173652461.png)



## 安装

看官方文档

![在这里插入图片描述](29.Docker%E9%AB%98%E7%BA%A7.assets/20201205173738412.png)

1、下载

```bash
sudo curl -L "https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose

# 这个下载会快点
curl -L https://get.daocloud.io/docker/compose/releases/download/1.25.0/docker-compose-`uname -s`-`uname -m` > /usr/local/bin/docker-compose
```

2、授权

```bash
sudo chmod +x docker-compose
```

3、查看版本

```bash
docker-compose version
```

![image-20211010205139499](29.Docker%E9%AB%98%E7%BA%A7.assets/image-20211010205139499.png)

## 体验

官方文档：https://docs.docker.com/compose/gettingstarted/

1、创建文件夹 composetest

```bash
$ mkdir composetest
$ cd composetest
```

2、创建 app.py

```bash
$ vim app.py

import time

import redis
from flask import Flask

app = Flask(__name__)
cache = redis.Redis(host='redis', port=6379)

def get_hit_count():
    retries = 5
    while True:
        try:
            return cache.incr('hits')
        except redis.exceptions.ConnectionError as exc:
            if retries == 0:
                raise exc
            retries -= 1
            time.sleep(0.5)

@app.route('/')
def hello():
    count = get_hit_count()
    return 'Hello World! I have been seen {} times.\n'.format(count)
```

3、创建 requirements.txt

```bash
$ vim requirements.txt

flask
redis
```

4、创建 Dockerfile

```bash
$ vim Dockerfile

FROM python:3.7-alpine
RUN sed -i 's/dl-cdn.alpinelinux.org/mirrors.aliyun.com/g' /etc/apk/repositories 
WORKDIR /code
ENV FLASK_APP=app.py
ENV FLASK_RUN_HOST=0.0.0.0
RUN apk add --no-cache gcc musl-dev linux-headers
COPY requirements.txt requirements.txt
RUN pip install -r requirements.txt
EXPOSE 5000
COPY . .
CMD ["flask", "run"]
```

5、创建 docker-compose.yml

```bash
$ vim docker-compose.yml

version: "3.8"
services:
  web:
    build: .
    ports:
      - "5000:5000"
  redis:
    image: "redis:alpine"
```

6、启动

```bash
$ docker-compose build
$ docker-compose up
```

7、停止

![在这里插入图片描述](29.Docker%E9%AB%98%E7%BA%A7.assets/20201206161110869.png)

![在这里插入图片描述](29.Docker%E9%AB%98%E7%BA%A7.assets/20201206161121213.png)

8、小结
![在这里插入图片描述](29.Docker%E9%AB%98%E7%BA%A7.assets/20201206161135882.png)

## yaml 规则

**docker-compose.yaml 核心！**
官方文档：https://docs.docker.com/compose/compose-file/

## 开源项目 - 博客

官方文档：https://docs.docker.com/compose/wordpress/
1、创建文件

```bash
$ mkdir my_wordpress
$ cd my_wordpress
$ vim docker-compose.yml

version: '3.3'

services:
   db:
     image: mysql:5.7
     volumes:
       - db_data:/var/lib/mysql
     restart: always
     environment:
       MYSQL_ROOT_PASSWORD: somewordpress
       MYSQL_DATABASE: wordpress
       MYSQL_USER: wordpress
       MYSQL_PASSWORD: wordpress

   wordpress:
     depends_on:
       - db
     image: wordpress:latest
     ports:
       - "8000:80"
     restart: always
     environment:
       WORDPRESS_DB_HOST: db:3306
       WORDPRESS_DB_USER: wordpress
       WORDPRESS_DB_PASSWORD: wordpress
       WORDPRESS_DB_NAME: wordpress
volumes:
    db_data: {}
```

2、启动

```bash
# 前台启动
$ docker-compose up
# 后台启动
$ docker-compose up -d
```

## 自己编写微服务上线

**需要有Java环境**

1、编写微服务项目（带redis和web）
HelloController.java

```java
package com.zhou.demo.controller;

import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.data.redis.core.StringRedisTemplate;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RestController;

@RestController
public class HelloController {

    @Autowired
    StringRedisTemplate redisTemplate;

    @GetMapping("/hello")
    public String hello(){
        Long views = redisTemplate.opsForValue().increment("views");
        return "Hello, thank you！ "+views;
    }
}

```

2、dockerfile构建镜像

```dockerfile
FROM java:12

COPY *.jar /app.jar

CMD ["--server.port=8080"]

EXPOSE 8080

ENTRYPOINT ["java","-jar","/app.jar"]
```

3、docker-compose.yml 编排项目

```yaml
version: '3.8'
services:
  zhouapp:
    build: .
    image: zhouapp
    depends_on:
      - redis
    ports:
      - "8080:8080"
  redis:
    image: "redis:alpine"

#  mysql:
#    ...
```

4、丢到服务器 docker-compose up

![image-20211012205503968](29.Docker%E9%AB%98%E7%BA%A7.assets/image-20211012205503968.png)

![image-20211012205540409](29.Docker%E9%AB%98%E7%BA%A7.assets/image-20211012205540409.png)

项目重新打包的命令

```bash
docker-compose up --build
```



访问项目：

![image-20211012205829674](29.Docker%E9%AB%98%E7%BA%A7.assets/image-20211012205829674.png)



总结：
![在这里插入图片描述](29.Docker%E9%AB%98%E7%BA%A7.assets/20201206174007707.png)

# Docker Swarm

#### 环境准备

- Docker compose 单机版；Docker swarm：集群方式部署；
- 腾讯云租4台服务器，1核 2G 按量付钱；预算五块，充值10元；按流量和租赁时间计费’

![在这里插入图片描述](29.Docker%E9%AB%98%E7%BA%A7.assets/20201121144841112.jpg)

- Xshell统一登陆
- 发送键输入到所有会话：执行同步环境安装操作，省时间

![在这里插入图片描述](29.Docker%E9%AB%98%E7%BA%A7.assets/2020112114484913.jpg)

![在这里插入图片描述](29.Docker%E9%AB%98%E7%BA%A7.assets/00bd3caec9ff0561a9bcd8ab5664d13e.png) 

![在这里插入图片描述](29.Docker%E9%AB%98%E7%BA%A7.assets/fed10ba825652da8956c4c501da0b779.png)



#### 工作模式



下面我们先了解一下swarm集群架构图

 ![在这里插入图片描述](29.Docker%E9%AB%98%E7%BA%A7.assets/20201121144859292.jpg)

swarm有三个角色，分别是管理者（manager）、工作者（worker）和被选举者（Reachable），管理者管理工作者。一般管理者节点也是一个工作者。被选举者是当管理者宕机后可被选举为管理者的节点。



- 两种节点：管理节点和工作节点



![image-20211012211811082](29.Docker%E9%AB%98%E7%BA%A7.assets/image-20211012211811082.png)

#### 搭建集群

```bash
#docker-01/02/03/04 查看网络情况、命令使用方法

docker network ls
docker swarm --help
---------------------------------------
#为了注册集群管理主节点：先预知参数和命令使用方法

docker swarm init --help
ip addr
eth0:172.16.0.11
---------------------------------------
#docker-01成为一个主管理节点：初始化节点

$ docker swarm init --advertise-addr 172.16.0.11

##说明：注册成功
Swarm initialized: current node (lb4ujyjftne3t0ojhb1o7nhhw) is now a manager.
To add a worker to this swarm, run the following command:
##说明：添加工作节点操作
    docker swarm join --token SWMTKN-1-30uc8rx1jk9v671nif6tw1otge9lyy3nj45xtzu1q7ehc4h793-8wpc388fnr1t7btyf91b041wj 172.16.0.11:2377
##说明：添加管理节点操作
To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.

#docker-02 加入为工作节点

docker swarm join --token SWMTKN-1-30uc8rx1jk9v671nif6tw1otge9lyy3nj45xtzu1q7ehc4h793-8wpc388fnr1t7btyf91b041wj 172.16.0.11:2377

#docker-01 两种方式成为该集群的管理节点或工作节点
docker node ls
docker swarm join-token manager
docker swarm join-token worker

#管理节点：生成管理节点或工作节点令牌
docker swarm join-token manager
docker swarm join-token worker
#非管理节点：通过令牌提示命令，执行成为集群的节点
```

总结步骤：生成init节点；加入集群（管理者，工作者）;目标双主双从；

#### RAFT协议

- 问题：假设一个节点挂了，其他节点是否可用？
- Raft协议：保证大多数节点存活；>1，集群>3
- 01 02 03 03 指的是四台服务器

```bash
#将docker1机器停止，宕机
#docker-01
systemctl stop docker
docker-02 docker-04
docker node ls
[root@VM-0-8-centos ~]# docker node ls
Error response from daemon: rpc error: code = DeadlineExceeded desc = context deadline exceeded

#docker-01
systemctl start docker

#docker-03
#工作节点变成管理节点
[root@VM-0-16-centos ~]# docker swarm join --token SWMTKN-1-30uc8rx1jk9v671nif6tw1otge9lyy3nj45xtzu1q7ehc4h793-e5cm85lrpbbcczmmggcsr99dv 172.16.0.8:2377
Error response from daemon: This node is already part of a swarm. Use "docker swarm leave" to leave this swarm and join another one.
[root@VM-0-16-centos ~]# docker swarm leave
Node left the swarm.
[root@VM-0-16-centos ~]# docker swarm join --token SWMTKN-1-30uc8rx1jk9v671nif6tw1otge9lyy3nj45xtzu1q7ehc4h793-e5cm85lrpbbcczmmggcsr99dv 172.16.0.8:2377
This node joined a swarm as a manager.

#docker-04
[root@VM-0-8-centos ~]# docker node ls
ID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS      ENGINE VERSION
pdc7fbmtypcqcgdbwkgfeixjo     VM-0-7-centos       Ready               Active                                  19.03.13
ddosg74pvzbil5cozcyuw4p5f *   VM-0-8-centos       Ready               Active              Leader              19.03.13
lb4ujyjftne3t0ojhb1o7nhhw     VM-0-11-centos      Ready               Active              Reachable           19.03.13
rp8zyu3xmulxwalabtvuqjw7v     VM-0-16-centos      Down                Active                                  19.03.13
sbpz4hqc6nps4e0ucxvd8o57g     VM-0-16-centos      Ready               Active              Reachable           19.03.13

#至此，将三台机器设置成，管理节点

#在三台管理节点满足高可用前提下，关闭其中一台docker服务，测试
01
[root@VM-0-11-centos ~]# systemctl stop docker

#docker-04 docker-03 照样可以使用
[root@VM-0-8-centos ~]# docker node ls
ID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS      ENGINE VERSION
pdc7fbmtypcqcgdbwkgfeixjo     VM-0-7-centos       Ready               Active                                  19.03.13
ddosg74pvzbil5cozcyuw4p5f *   VM-0-8-centos       Ready               Active              Leader              19.03.13
lb4ujyjftne3t0ojhb1o7nhhw     VM-0-11-centos      Ready               Active              Unreachable         19.03.13
rp8zyu3xmulxwalabtvuqjw7v     VM-0-16-centos      Down                Active                                  19.03.13
sbpz4hqc6nps4e0ucxvd8o57g     VM-0-16-centos      Ready               Active              Reachable    
```

总结:集群要保证可用，必须要 至少3个主节点；且保证一台管理节点存货；Raft协议保证大部分节点存活才可以使用；

#### 体会

- 使用swarm之后所有操作都属于集群操作范畴
- 应该拥有：弹性，扩缩容，集群

>docker run 单机模式下：基础模式/告别
>
>docker-compose up 单机模式下：启动一个项目上线！
>
>docker service 集群swarm下集群节点
>
>k8s service pods
>
>容器变成服务（服务中有个概念叫做副本）：redis 多份！单独来说多个容器
>
>集群：高可用，web->redis (3台)，分布在不同机器上！

- docker service功能：创建服务，动态扩展服务，动态更新服务
- 灰度发布：金丝雀发布！滚动发布：升级服务不影响旧版使用

```bash
docker service --help
```

```bash
#工作节点启动服务失败
[root@VM-0-7-centos ~]# docker service create -p 8888:80 --name mynginx nginx
Error response from daemon: This node is not a swarm manager. Worker nodes can't be used to view or modify cluster state. Please run this command on a manager node or promote the current node to a manager.

#管理节点操作
[root@VM-0-16-centos ~]#  docker service create -p 8888:80 --name mynginx nginx
2qcjcuwkex4a7j0z5ee5pp1du
overall progress: 1 out of 1 tasks 
1/1: running   
verify: Service converged 

#总结：docker run      容器启动！不具有扩缩容器
#     docker swervice 服务！具有扩缩容器，滚动更新

# docker-管理节点查看
[root@VM-0-16-centos ~]# docker service ps mynginx
ID                  NAME                IMAGE               NODE                DESIRED STATE       CURRENT STATE           ERROR               PORTS
2mml3eiankpd        mynginx.1           nginx:latest        VM-0-8-centos       Running             Running 2 minutes ago  
[root@VM-0-11-centos ~]# docker service ls
ID                  NAME                MODE                REPLICAS            IMAGE               PORTS
2qcjcuwkex4a        mynginx             replicated          1/1                 nginx:latest        *:8888->80/tcp

```

**查看服务 REPLICAS**

- 启动服务在管理节点主机里随机启动

```bash
#上述启动nginx服务情况只是启动一个副本

#现在给其他两个管理节点增加 服务副本
[root@VM-0-11-centos ~]# docker service update --replicas 3 mynginx
mynginx
overall progress: 3 out of 3 tasks 
1/3: running   
2/3: running   
3/3: running   
verify: Service converged 
#只要在集群里面，无论访问哪个ip都可以访问服务；
#集群为单位的机器
```

![在这里插入图片描述](29.Docker%E9%AB%98%E7%BA%A7.assets/20201121144919564.jpg)

- 动态扩缩容

```bash
#1.扩容测试
[root@VM-0-11-centos ~]# docker service update --replicas 10 mynginx
mynginx
overall progress: 9 out of 9 tasks 
1/9: running   
2/9: running   
3/9: running   
4/9: running   
5/9: running   
6/9: running   
7/9: running   
8/9: running   
9/9: running   
verify: Service converged 
[root@VM-0-8-centos ~]# docker service ls
ID                  NAME                MODE                REPLICAS            IMAGE               PORTS
2qcjcuwkex4a        mynginx             replicated          9/9                 nginx:latest        *:8888->80/tcp

#总结：因为容器之间是相互隔离，所以开多少个容器取决于硬件条件允许，一个服务器节点可以同时开多个服务；
#一个服务可以有多个副本，动态扩缩容，实现高可用

#2.缩容测试
#mynginx 服务回滚到一个副本
[root@VM-0-16-centos ~]# docker service update --replicas 1 mynginx
mynginx
overall progress: 1 out of 1 tasks 
1/1: running   
verify: Service converged 
[root@VM-0-16-centos ~]# docker service ls
ID                  NAME                MODE                REPLICAS            IMAGE               PORTS
2qcjcuwkex4a        mynginx             replicated          1/1                 nginx:latest        *:8888->80/tcp


#3.另一种方式的扩缩容命令
[root@VM-0-16-centos ~]# docker service scale mynginx=5
mynginx scaled to 5
overall progress: 5 out of 5 tasks 
1/5: running   
2/5: running   
3/5: running   
4/5: running   
5/5: running   
verify: Service converged 
[root@VM-0-11-centos ~]# docker service ls
ID                  NAME                MODE                REPLICAS            IMAGE               PORTS
2qcjcuwkex4a        mynginx             replicated          5/5                 nginx:latest        *:8888->80/tcp


#4.移除服务
[root@VM-0-8-centos ~]# docker service rm mynginx
mynginx
[root@VM-0-8-centos ~]# docker service ps mynginx
no such service: mynginx
[root@VM-0-8-centos ~]# docker service ls
ID                  NAME                MODE                REPLICAS            IMAGE               PORTS
```

> 总结：
>
> 弹性，扩缩容非常重要；
> 副本 所对应的服务既可以运行在管理节点也可以运行在工作节点；
> 集群搭建好，服务创建好，任何集群内的ip地址都可以访问集群所提供的服务；
> 一个服务可以有多个副本，动态扩缩容，实现高可用；
> 只要会用docker swarm 搭建集群 docker service create 启动服务，docker service scale 或者docker service update 动态管理容器就可以了

#### 概括总结

**swarn**

- 集群的管理和编排（好比厨房），docker可以初始化一个集群，其他节点可以加入；（管理节点，工作节点）
- 命令->管理节点->api->调度->工作节点（创建task容器，维护创建）

![在这里插入图片描述](29.Docker%E9%AB%98%E7%BA%A7.assets/20201121144937663.jpg)

**Node**

- 一个Dokcer节点（好比餐桌），多个节点就组成一个网络集群；（管理节点，工作节点）

**Service**

- 任务群（好比一个做菜清单），可以在管理节点或者工作节点来运行；核心。用户访问；

![在这里插入图片描述](29.Docker%E9%AB%98%E7%BA%A7.assets/20201121144948954.jpg)

**Task**

- 容器内的命令=细节任务（好比做菜清单的一道菜）；一个Service有多个task，由集群来调度由哪个node来完成

![在这里插入图片描述](29.Docker%E9%AB%98%E7%BA%A7.assets/20201121145000863.jpg)

**Replicas**

- 服务副本与全局服务

![在这里插入图片描述](29.Docker%E9%AB%98%E7%BA%A7.assets/20201121145011626.jpg)

```bash
--mode string 
docker service create --mode replicated --name mytom tomcat:7.0
docker service create --mode replicated --name haha xixi ping baidu.com
```

网络模式

overlay
ingress：特殊的overlay网络，具有负载均衡功能！IPVS VIP。
docker在多台机器上，实际上是同一个ingress网络vip，让集群变成一个整体
多台服务器搭建成集群，为了能让他们互相ping通，搭建一个网络，使得他们可以互相ping通
Docker-Stack

Docker-compose：单机玩具，单机部署项目
Docker-Stack：集群部署

```bash
#单机
docker-compose up -d wordpress.yaml
#集群
docker stack --help
docker-stack deploy wordpress.yaml

#docker-compose 文件
#百度:docker stack 案例

#集群下的yaml中service层的字段：deploy：... 
```

# **Docer-Secret**

- 安全！配置密码，证书！

```bash
docker secret --help
```

# **Docker Config**

**学习方式**

- 网上/开源社区，找案例跑起来！查看命令帮助文档（–help,官网）
- 学习一次总结一次，最后达成对整个知识群的把握。

# K8s
### 云原生时代

云应用（商店）：项目不用开发，直接云应用下载，新手也可以自己搭建大型网站
买服务器->部署K8s->云应用下载下来->自己配置->变成自己的平台
大趋势/10台机器以上



###### 学习清单

```bash
Go语言：Docker，K8s，存储ETCD；Go是并发语言；
特性：语法类似C，内存安全，垃圾回收，结构形态，并发计算
建议：先学Go再学K8s效果会更好；
方法：入门，基础语法，高级对象，操作数据库，框架

K8s：

Jenkins：
```

### 虚拟化技术概念

#### KVM

* KVM虚拟化技术属于全虚拟化技术，KVM作为一个运行在主机操作系统的虚拟化软件工具，客户操作系统根据需要运行在KVM虚拟化环境里，在这个环境里，当一个进程要使用CPU指令（特权指令，普通指令），客户操作系统认为自己运行在硬件上，直接对虚拟化的CPU进行调用，但它本身无法执行的，必须经过封装的接口，将其转化为主机操作系统的指令进行调用，进而通过真正的内核对真正的CPU的指令做调用，所以你就明白了[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-GmZuDKWR-1605940890881)(C:/Users/Administrator/Desktop/2020-10-26_180639.jpg)]中间为了进行真正的指令转化，需要消耗一部分资源。

* KVM是一个硬件资源虚拟化的软件工具

* 一方面，KVM工具本身能将CPU和硬盘资源虚拟化，另一方面，为了补齐KVM的短板，实现更加人性化的虚拟化服务，引入qemu工具实现网络和其他I/O设备的虚拟化模拟

* KVM运行在内核空间，但是QEMU运行在用户空间

* 需要安装什么工具：

* libvirt qemu-kvm

* libvirtd是虚拟机的管理工具，通过virsh管理虚拟机，用它来cpu动态扩容，内存动态调整

* 用qemu-img来进行磁盘管理

#### Docker

* 容器技术，基于Go语言，遵循Apache2.0协议，虚拟化了谁，虚拟化了内核，即虚拟化的不是硬件层是操作系统层。所以什么，我们可以不用虚拟机同样可以运行Docker容器，提高了资源的利用率。

* 这就意味着 Docker既可以运行在虚拟机操作系统上也可以运行在主机操作系统上；

* 服务器虚拟化解决的是资源调配问题；而容器解决的核心是应用开发测试和部署

* docker由服务器端和客户端组成

* docker组件：镜像，容器，仓库

* 镜像组件，涉及到镜像的搜索，获取，导出，导入，查看，删除

* 容器组件，涉及到容器的创建，运行，进入，删除；运行什么，运行镜像+指定命令 docker run

* 仓库组件

* 网络访问：随机映射，指定映射，查看映射

* 数据管理：不同容器之间可以共享数据

* 如何构建Docker镜像 主要是编辑Dockerfile文件 docker build

* docker应对生产情况架构是什么，底层系统层，中间是运行环境层，顶层是应用服务层；系统层可以是centos，ubuntu，debain系统；运行环境层可以是php，java，python；应用服务层比较多不一一列举

* 设计一个适用于特定场景的docker也是要遵守上面这三层的结构

#### K8S+Docker+Ceph+ISTIO+Enovy

Docker：容器化技术，应用部署

Kuberneates：容器编排，云平台上的多主机的容器化应用管理

Istio：已部署的服务建立网络，具有负载均衡，服务间认证，监控

Envoy：构建高性能服务间的通信系统，实现边缘和服务代理，用于云原生应用

Ceph：分布式存储系统，中大型架构支持 